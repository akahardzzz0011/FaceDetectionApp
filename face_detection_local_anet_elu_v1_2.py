# -*- coding: utf-8 -*-
"""face_detection_local_aNet_elu_v1.2.ipynb

Automatically generated by Colaboratory.

"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import os
import pandas as pd
from PIL import Image
import seaborn as sns
from datetime import datetime
# %load_ext tensorboard
from keras.utils import load_img
from tqdm.notebook import tqdm
from keras.callbacks import ModelCheckpoint, TensorBoard
from tensorflow.keras import Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten,\
     BatchNormalization, Dropout, Input

#@title Run if hosted runtime
from google.colab import drive
drive.mount("/content/gdrive")

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir "/content/gdrive/My Drive/logs/aNet_elu20230304-202759/"

#@title Change paths based on model 
dataset_path = 
model_path = 
test_folder_path = 
log_path = 
log_save_path = log_path + datetime.now().strftime("%Y%m%d-%H%M%S")

def age_to_class(age):
  if 0 <= age <= 2:
    return 0
  elif 3 <= age <= 9:
    return 1
  elif 10 <= age <= 20:
    return 2
  elif 21 <= age <= 27:
    return 3
  elif 28 <= age <= 45:
    return 4
  elif 46 <= age <= 65:
    return 5
  else:
    return 6

#@title Read the images from dir path
def read_from_directory(dataset_path, age_to_class):
  image_paths = []
  age_labels = []
  age_groups = []
  gender_labels = []
  ethnicity_labels = []
  for dirname, _, filenames in os.walk(dataset_path):
    for filename in filenames:
      image_path = os.path.join(dirname, filename)
      splitted = filename.split('_')
      age = int(splitted[0])
      gender = int(splitted[1])
      ethnicity = int(splitted[2])
      image_paths.append(image_path)
      age_labels.append(age)
      age_groups.append(age_to_class(age))
      gender_labels.append(gender)
      ethnicity_labels.append(ethnicity)
  return image_paths, age_labels, age_groups, gender_labels, ethnicity_labels

image_paths = []
age_labels = []
age_groups = []
gender_labels = []
ethnicity_labels = []
image_paths, age_labels, age_groups, gender_labels, ethnicity_labels = read_from_directory(dataset_path, age_to_class)
age_map = {0:'(0-2)', 1:'(3-9)', 2:'(10-20)', 3:'(21-27)', 4:'(28-45)', 5:'(46-65)',
              6:'(66-116)'}
gender_map = {0:'male', 1:'female'}
ethnicity_map = {0:'white', 1:'black', 2:'asian', 3:'indian', 4:'hispanic'}

df = pd.DataFrame()
df['image'], df['age'], df['age_groups'], df['gender'], df['ethnicity'] = image_paths, age_labels, age_groups, gender_labels, ethnicity_labels
df.head()

len(df['image'])

img = Image.open(df['image'][55])
img

plt.figure(figsize=(20, 20))
files = df.iloc[0:16]

for i, image_file, age, age_group, gender, ethnicity in files.itertuples():
  plt.subplot(4, 4, i+1)
  img = load_img(image_file)
  img = np.array(img)
  plt.imshow(img)
  plt.title(f"Age: {age} {age_map[age_group]}\nGender: {gender_map[gender]}\nEthnicity: {ethnicity_map[ethnicity]}")
  plt.axis('off')

sns.displot(df['gender'], aspect=3, height=5)

df.groupby(['gender']).count()

images = []
image_width, image_height = 128, 128
for image in df['image'][0:4000]:
  img = load_img(image)
  img = img.resize((image_width, image_height), Image.ANTIALIAS)
  img = np.array(img)
  images.append(img)
  
X_images = np.array(images)
X_images = X_images / 255.0
y_age = np.array(df['age'])
y_age_group = np.array(df['age_groups'])
y_gender = np.array(df['gender'])
y_ethnicity = np.array(df['ethnicity'])

#@title Initialize The Model
def layer_stack(inputs):
  In = inputs
  C1 = Conv2D(filters = 96, kernel_size = (11, 11), strides = (4, 4),
              padding = 'valid', activation = 'elu') (In)
  S2 = MaxPooling2D(pool_size= (3, 3), strides = (2, 2),
                    padding = 'valid') (C1)
  C3 = Conv2D(filters = 256, kernel_size = (5, 5), strides = (1, 1),
              padding = 'same', activation = 'elu') (S2)
  S4 = MaxPooling2D(pool_size= (3, 3), strides = (2, 2), 
                    padding = 'valid') (C3)
  C5 = Conv2D(filters = 384, kernel_size = (3, 3), strides = (1, 1),
              padding = 'same', activation = 'elu') (S4)
  C6 = Conv2D(filters = 384, kernel_size = (3, 3), strides = (1, 1),
                     padding = 'same', activation = 'elu') (C5)
  C7 = Conv2D(filters = 256, kernel_size = (3, 3), strides = (1, 1),
                     padding = 'same', activation = 'elu') (C6)
  S8 = MaxPooling2D(pool_size= (3, 3), strides = (2, 2),
                           padding = 'valid') (C7)
  return S8

def age_output(inputs):
  F1 = Flatten() (inputs)
  D2 = Dense(256, activation = 'elu') (F1)
  D3 = Dense(256, activation = 'elu') (D2)
  D4 = Dense(1, activation = "elu", name = 'age_output') (D3)
  return D4

def age_group_output(inputs, age_group_amount):
  F1 = Flatten() (inputs)
  D2 = Dense(256, activation = 'elu') (F1)
  D3 = Dense(256, activation = 'elu') (D2)
  D4 = Dropout(0.4) (D3)
  B5 = BatchNormalization() (D4)
  D4 = Dense(age_group_amount, activation = "softmax", name = 'age_group_output') (B5)
  return D4

def gender_output(inputs, gender_amount):
  F1 = Flatten() (inputs)
  D2 = Dense(256, activation = 'elu') (F1)
  D3 = Dense(256, activation = 'elu') (D2)
  D4 = Dropout(0.4) (D3)
  B5 = BatchNormalization() (D4)
  D4 = Dense(gender_amount, activation = "softmax", name = 'gender_output') (B5)
  return D4

def ethnicity_output(inputs, ethnicity_amount):
  F1 = Flatten() (inputs)
  D2 = Dense(256, activation = 'elu') (F1)
  D3 = Dense(256, activation = 'elu') (D2)
  D4 = Dropout(0.4) (D3)
  B5 = BatchNormalization() (D4)
  D4 = Dense(ethnicity_amount, activation = "softmax", name = 'ethnicity_output') (B5)
  return D4


def the_model(width, height, age_group_amount, gender_amount, ethnicity_amount):
  input_shape = (width, height, 3)
  inputs = Input(shape = input_shape)
  layer_stack_out = layer_stack(inputs)
  age_out = age_output(layer_stack_out)
  age_group_out = age_group_output(layer_stack_out, age_group_amount)
  gender_out = gender_output(layer_stack_out, gender_amount)
  ethnicity_out = ethnicity_output(layer_stack_out, ethnicity_amount)

  model = Model(inputs = inputs, outputs = [age_out, age_group_out, gender_out, ethnicity_out],
                name = 'the_network')
  return model

model = the_model(image_width, image_height, len(age_map), len(gender_map), len(ethnicity_map))

model.summary()

from tensorflow.keras.utils import plot_model
plot_model(model)

#@title Callback to save weigths
save_best = ModelCheckpoint(model_path,
                            monitor = 'val_age_group_output_accuracy',
                            verbose = 0,
                            save_best_only = True,
                            mode = 'max',
                            save_freq = 'epoch'
                            )

#@title Save epoch logs
logs = TensorBoard(log_dir = log_save_path)

model.compile(optimizer = 'adam',
              loss = {'age_output': 'mae',
                      'age_group_output': 'sparse_categorical_crossentropy',
                      'gender_output': 'sparse_categorical_crossentropy',
                      'ethnicity_output': 'sparse_categorical_crossentropy'
                      },
              
              metrics = {'age_output': 'mean_absolute_percentage_error', 
                         'age_group_output':'accuracy',
                         'gender_output': 'accuracy',
                         'ethnicity_output': 'accuracy'
                         }
              )

#@title Train The Model
history = model.fit(x = X_images, y = [y_age, y_age_group, y_gender, y_ethnicity], batch_size = 64, epochs = 80,
                    validation_split = 0.2,
                    callbacks=[save_best, logs]
                  )

#@title Save The Model as H5 format
model.save( "pathname", save_format='h5')

#@title Save the data into .csv file
hist_df = pd.DataFrame(history.history)
hist_csv_file = 'history_model_v1.2.csv'
with open(hist_csv_file, mode='w') as f:
  hist_df.to_csv(f)

#@title Load The Model
model = tf.keras.models.load_model(model_path)

#@title Analyze Training Data Results
index = 2

print("Real age: ", y_age[index])

pred = model.predict(X_images[index].reshape(1, image_width, image_height, 3))
print("Pred regression age:", round(pred[0][0][0]))
print("Pred classification age:", age_map[np.argmax(pred[1])])
print("Pred gender:", gender_map[np.argmax(pred[2])])
print("Pred ethnicity: ", ethnicity_map[np.argmax(pred[3])])
img = Image.open(df['image'][index])
img

#@title Plotted Testing Data
plt.figure(figsize=(16, 16))
image_width, image_height = 128, 128
for i in range(20):
  files = df.iloc[i + 10000]
  img = np.array(Image.open(files.image).resize((image_width, image_height))) / 255.0
  pred = model.predict(np.array([img]))
  plt.subplot(5, 4, i + 1)
  plt.subplots_adjust(top=1.4)
  reg_age = round(pred[0][0][0])
  class_age = age_map[np.argmax(pred[1])]
  gender = gender_map[np.argmax(pred[2])]
  ethnicity = ethnicity_map[np.argmax(pred[3])]
  plt.axis('off')
  plt.title(f'Actual Age:{files.age} AgeGuess: {reg_age} \nGroup: {class_age}\
            \nGender: {gender} Actual: {gender_map[files.gender]} \nEthnicity: {ethnicity} Actual: {ethnicity_map[files.ethnicity]}', pad=20)
  plt.imshow(img)

#@title Feed Test Data
test_img_filepath = []
filename_array = []

for dirname, _, filenames in os.walk(test_folder_path):
  for filename in filenames:
    test_image_path = os.path.join(dirname, filename)
    test_img_filepath.append(test_image_path)
    filename_array.append(filename)

df_test = pd.DataFrame()
df_test['image_test'] = test_img_filepath
df_test.head()

test_images = []
for image in tqdm(df_test['image_test']):
  img = load_img(image)
  img = img.resize((image_width, image_height), Image.ANTIALIAS)
  img = np.array(img)
  test_images.append(img)

x_test = np.array(test_images)
x_test = x_test / 255.0

index = 2

pred = model.predict(x_test[index].reshape(1, image_width, image_height, 3))
print("Pred regression age:", round(pred[0][0][0]))
print("Pred classification age:", age_map[np.argmax(pred[1])])
img = Image.open(df_test['image_test'][index])
irez = img.resize((image_width, image_height))
irez
